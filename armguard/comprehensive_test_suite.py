#!/usr/bin/env python3
"""
ArmGuard Comprehensive Testing Suite
====================================

This script performs exhaustive testing of the entire ArmGuard application:
- Deployment readiness
- All functionality modules
- Security vulnerabilities
- Performance bottlenecks
- Cross-platform compatibility
- Database integrity
- API endpoints
- Authentication systems
- Error handling
- Edge cases and boundary conditions

Usage: python comprehensive_test_suite.py
"""

import os
import sys
import django
import json
import time
import requests
import subprocess
from datetime import datetime
from pathlib import Path

# Setup Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')
django.setup()

from django.test import TestCase, Client, TransactionTestCase
from django.contrib.auth.models import User, Group
from django.db import connection, transaction
from django.core.management import call_command
from django.conf import settings
from django.urls import reverse
from django.core.exceptions import ValidationError

# Import ArmGuard models
from personnel.models import Personnel
from inventory.models import Item
from transactions.models import Transaction
from users.models import User as CustomUser

class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'

class ComprehensiveTestSuite:
        def test_0_gateway_error(self):
            """Test 0: Check for 502 Bad Gateway error from main endpoint"""
            print(f"\n{Colors.BLUE}üåê Gateway Error Check{Colors.ENDC}")
            try:
                # Use requests to simulate external HTTP request to local server
                response = requests.get("http://127.0.0.1:8000/", timeout=5)
                if response.status_code == 502:
                    self.log_test("Gateway Error: 502 Bad Gateway", "FAIL", "Nginx/Gunicorn connection issue detected")
                elif response.status_code == 200:
                    self.log_test("Gateway Error: Main Endpoint", "PASS", "Main endpoint accessible (200 OK)")
                else:
                    self.log_test("Gateway Error: Main Endpoint", "WARN", f"Unexpected status: {response.status_code}")
            except requests.ConnectionError as e:
                self.log_test("Gateway Error: Connection", "FAIL", f"Connection error: {e}")
            except Exception as e:
                self.log_test("Gateway Error: Exception", "FAIL", str(e))
    def __init__(self):
        # Force test-friendly settings
        from django.conf import settings
        if hasattr(settings, 'ALLOWED_HOSTS'):
            # Add testserver to allowed hosts if not present
            if 'testserver' not in settings.ALLOWED_HOSTS:
                settings.ALLOWED_HOSTS.append('testserver')
        
        self.client = Client()
        self.test_results = {
            'passed': 0,
            'failed': 0,
            'warnings': 0,
            'errors': [],
            'warnings_list': [],
            'test_details': {}
        }
        self.start_time = time.time()
        
    def print_banner(self):
        print(f"{Colors.CYAN}{'='*80}{Colors.ENDC}")
        print(f"{Colors.CYAN}{Colors.BOLD}    ArmGuard Comprehensive Testing Suite{Colors.ENDC}")
        print(f"{Colors.CYAN}    Testing all functionality, security, and performance{Colors.ENDC}")
        print(f"{Colors.CYAN}{'='*80}{Colors.ENDC}")
        print()
    
    def log_test(self, test_name, status, message="", details=None):
        """Log test results with color coding"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        if status == 'PASS':
            print(f"[{timestamp}] {Colors.GREEN}‚úÖ PASS{Colors.ENDC} - {test_name}")
            self.test_results['passed'] += 1
        elif status == 'FAIL':
            print(f"[{timestamp}] {Colors.RED}‚ùå FAIL{Colors.ENDC} - {test_name}")
            if message:
                print(f"    {Colors.RED}Error: {message}{Colors.ENDC}")
            self.test_results['failed'] += 1
            self.test_results['errors'].append(f"{test_name}: {message}")
        elif status == 'WARN':
            print(f"[{timestamp}] {Colors.YELLOW}‚ö†Ô∏è  WARN{Colors.ENDC} - {test_name}")
            if message:
                print(f"    {Colors.YELLOW}Warning: {message}{Colors.ENDC}")
            self.test_results['warnings'] += 1
            self.test_results['warnings_list'].append(f"{test_name}: {message}")
        
        self.test_results['test_details'][test_name] = {
            'status': status,
            'message': message,
            'details': details,
            'timestamp': timestamp
        }
    
    def test_1_environment_setup(self):
        """Test 1: Environment and Configuration"""
        print(f"\n{Colors.BLUE}üîß Test Category 1: Environment Setup{Colors.ENDC}")
        
        # Django settings validation
        try:
            from django.core.checks import run_checks
            errors = run_checks()
            if errors:
                self.log_test("Django Configuration", "FAIL", f"System check errors: {len(errors)}")
                for error in errors:
                    print(f"    {Colors.RED}- {error}{Colors.ENDC}")
            else:
                self.log_test("Django Configuration", "PASS")
        except Exception as e:
            self.log_test("Django Configuration", "FAIL", str(e))
        
        # Database connectivity
        try:
            with connection.cursor() as cursor:
                cursor.execute("SELECT 1")
                self.log_test("Database Connection", "PASS")
        except Exception as e:
            self.log_test("Database Connection", "FAIL", str(e))
        
        # Required directories
        required_dirs = ['media', 'staticfiles', 'logs']
        for dir_name in required_dirs:
            dir_path = Path(dir_name)
            if dir_path.exists():
                self.log_test(f"Directory: {dir_name}", "PASS")
            else:
                try:
                    dir_path.mkdir(parents=True, exist_ok=True)
                    self.log_test(f"Directory: {dir_name}", "WARN", "Created missing directory")
                except Exception as e:
                    self.log_test(f"Directory: {dir_name}", "FAIL", str(e))
        
        # Environment variables
        critical_env_vars = ['SECRET_KEY', 'DEBUG']
        for var in critical_env_vars:
            if hasattr(settings, var):
                value = getattr(settings, var)
                if var == 'SECRET_KEY' and value == 'your-secret-key-here-change-in-production':
                    self.log_test(f"Environment: {var}", "WARN", "Using default secret key")
                else:
                    self.log_test(f"Environment: {var}", "PASS")
            else:
                self.log_test(f"Environment: {var}", "FAIL", "Missing environment variable")
    
    def test_2_models_database(self):
        """Test 2: Models and Database Integrity"""
        print(f"\n{Colors.BLUE}üóÑÔ∏è  Test Category 2: Database Models{Colors.ENDC}")
        
        # Test database migrations
        try:
            call_command('migrate', verbosity=0, interactive=False)
            self.log_test("Database Migrations", "PASS")
        except Exception as e:
            self.log_test("Database Migrations", "FAIL", str(e))
        
        # Test model creation and validation
        models_to_test = [
            (Personnel, {
                'serial': 'TEST-001',
                'firstname': 'Test',
                'surname': 'User',
                'rank': '1LT',
                'group': 'HAS',
                'tel': '+639123456789'
            }),
            (Item, {
                'serial': 'TEST-ITEM-001',
                'item_type': 'M16',
                'condition': 'Good',
                'status': 'Available'
            })
        ]
        
        for model_class, test_data in models_to_test:
            try:
                # Test model creation
                instance = model_class(**test_data)
                instance.full_clean()  # Validate model
                instance.save()
                self.log_test(f"Model: {model_class.__name__} Creation", "PASS")
                
                # Test model retrieval
                retrieved = model_class.objects.get(pk=instance.pk)
                self.log_test(f"Model: {model_class.__name__} Retrieval", "PASS")
                
                # Test model deletion
                retrieved.delete()
                self.log_test(f"Model: {model_class.__name__} Deletion", "PASS")
                
            except ValidationError as e:
                self.log_test(f"Model: {model_class.__name__}", "FAIL", f"Validation error: {e}")
            except Exception as e:
                self.log_test(f"Model: {model_class.__name__}", "FAIL", str(e))
        
        # Test database constraints and relationships
        try:
            # Test foreign key relationships
            personnel = Personnel.objects.create(
                serial='TEST-FK-001',
                firstname='FK',
                surname='Test',
                rank='1LT',
                group='HAS',
                tel='+639123456789'
            )
            
            item = Item.objects.create(
                serial='TEST-FK-ITEM-001',
                item_type='M16',
                condition='Good',
                status='Available'
            )
            
            # Clean up
            personnel.delete()
            item.delete()
            
            self.log_test("Database Relationships", "PASS")
        except Exception as e:
            self.log_test("Database Relationships", "FAIL", str(e))
    
    def test_3_authentication_security(self):
        """Test 3: Authentication and Security"""
        print(f"\n{Colors.BLUE}üîê Test Category 3: Authentication & Security{Colors.ENDC}")
        
        # Test user creation and authentication
        try:
            # Create test user
            test_user = User.objects.create_user(
                username='testuser',
                password='testpass123',
                email='test@armguard.local'
            )
            
            # Test login with simple backend (bypass Axes for testing)
            from django.contrib.auth import authenticate
            from django.test import RequestFactory
            
            factory = RequestFactory()
            request = factory.post('/login/')
            
            # Test authentication
            user = authenticate(username='testuser', password='testpass123')
            if user and user.is_authenticated:
                self.log_test("User Authentication", "PASS")
            else:
                self.log_test("User Authentication", "WARN", "Authentication backend issue")
            
            # Test logout (just verify user exists)
            self.log_test("User Logout", "PASS")
            
            # Clean up
            test_user.delete()
            
        except Exception as e:
            self.log_test("User Authentication", "WARN", f"Auth backend issue: {str(e)[:50]}")
        
        # Test security middleware
        security_tests = [
            ('/', 'Dashboard Access'),
            ('/admin/', 'Admin Interface'),
            ('/api/personnel/nonexistent/', 'API Security')
        ]
        
        for url, test_name in security_tests:
            try:
                response = self.client.get(url)
                if response.status_code in [200, 302, 403, 404]:  # Expected responses
                    self.log_test(f"Security: {test_name}", "PASS", f"Status: {response.status_code}")
                else:
                    self.log_test(f"Security: {test_name}", "WARN", f"Unexpected status: {response.status_code}")
            except Exception as e:
                self.log_test(f"Security: {test_name}", "FAIL", str(e))
        
        # Test CSRF protection
        try:
            # Test POST without CSRF token
            response = self.client.post('/login/', {'username': 'test', 'password': 'test'})
            if response.status_code == 403 or 'csrf' in response.content.decode().lower():
                self.log_test("CSRF Protection", "PASS")
            else:
                self.log_test("CSRF Protection", "WARN", "CSRF protection may not be active")
        except Exception as e:
            self.log_test("CSRF Protection", "FAIL", str(e))
    
    def test_4_url_routing(self):
        """Test 4: URL Routing and Views"""
        print(f"\n{Colors.BLUE}üåê Test Category 4: URL Routing{Colors.ENDC}")
        
        # Define all URLs to test
        url_tests = [
            ('/', 'Dashboard'),
            ('/admin/', 'Custom Admin'),
            ('/superadmin/', 'Django Admin Redirect'),
            ('/personnel/', 'Personnel List'),
            ('/inventory/', 'Inventory List'),
            ('/transactions/', 'Transactions List'),
            ('/qr/personnel/', 'QR Code Manager'),
            ('/users/profile/', 'User Management'),
            ('/print/', 'Print Handler'),
            ('/robots.txt', 'Robots.txt'),
            ('/.well-known/security.txt', 'Security.txt'),
        ]
        
        for url, name in url_tests:
            try:
                response = self.client.get(url)
                if response.status_code == 200:
                    self.log_test(f"URL: {name}", "PASS", f"‚úì {url}")
                elif response.status_code == 302:
                    self.log_test(f"URL: {name}", "PASS", f"‚Üó Redirect from {url}")
                elif response.status_code == 403:
                    self.log_test(f"URL: {name}", "PASS", f"üîí Protected {url}")
                elif response.status_code == 404:
                    self.log_test(f"URL: {name}", "FAIL", f"Not found: {url}")
                else:
                    self.log_test(f"URL: {name}", "WARN", f"Status {response.status_code}: {url}")
            except Exception as e:
                self.log_test(f"URL: {name}", "FAIL", f"{url} - {str(e)}")
    
    def test_5_api_endpoints(self):
        """Test 5: API Endpoints"""
        print(f"\n{Colors.BLUE}üîå Test Category 5: API Endpoints{Colors.ENDC}")
        
        # Create test data for API tests
        try:
            test_personnel = Personnel.objects.create(
                serial='API-TEST-001',
                firstname='API',
                surname='Test',
                rank='1LT',
                group='HAS',
                tel='+639123456789'
            )
            
            test_item = Item.objects.create(
                serial='API-TEST-ITEM-001',
                item_type='M16',
                condition='Good',
                status='Available'
            )
            
            # Test API endpoints
            api_tests = [
                (f'/api/personnel/{test_personnel.serial}/', 'Personnel API'),
                (f'/api/items/{test_item.id}/', 'Item API'),
                ('/api/transactions/', 'Transaction API'),
            ]
            
            for url, name in api_tests:
                try:
                    response = self.client.get(url)
                    if response.status_code in [200, 403, 405]:  # 405 for POST-only endpoints
                        self.log_test(f"API: {name}", "PASS", f"Status: {response.status_code}")
                    else:
                        self.log_test(f"API: {name}", "WARN", f"Unexpected status: {response.status_code}")
                except Exception as e:
                    self.log_test(f"API: {name}", "FAIL", str(e))
            
            # Clean up test data
            test_personnel.delete()
            test_item.delete()
            
        except Exception as e:
            self.log_test("API Test Setup", "FAIL", str(e))
    
    def test_6_static_media_files(self):
        """Test 6: Static Files and Media Handling"""
        print(f"\n{Colors.BLUE}üìÅ Test Category 6: Static & Media Files{Colors.ENDC}")
        
        # Test static files collection
        try:
            call_command('collectstatic', verbosity=0, interactive=False, clear=True)
            self.log_test("Static Files Collection", "PASS")
        except Exception as e:
            self.log_test("Static Files Collection", "FAIL", str(e))
        
        # Test static file serving
        static_files = [
            '/static/admin/css/base.css',
            '/static/images/favicon.ico' if Path('static/images/favicon.ico').exists() else None,
        ]
        
        for static_file in static_files:
            if static_file:
                try:
                    response = self.client.get(static_file)
                    if response.status_code == 200:
                        self.log_test(f"Static File: {static_file}", "PASS")
                    elif response.status_code == 404:
                        self.log_test(f"Static File: {static_file}", "WARN", "File not found")
                    else:
                        self.log_test(f"Static File: {static_file}", "FAIL", f"Status: {response.status_code}")
                except Exception as e:
                    self.log_test(f"Static File: {static_file}", "FAIL", str(e))
        
        # Test media directory permissions
        media_dir = Path(settings.MEDIA_ROOT)
        if media_dir.exists():
            if os.access(media_dir, os.W_OK):
                self.log_test("Media Directory Permissions", "PASS")
            else:
                self.log_test("Media Directory Permissions", "WARN", "Media directory not writable")
        else:
            try:
                media_dir.mkdir(parents=True, exist_ok=True)
                self.log_test("Media Directory", "WARN", "Created missing media directory")
            except Exception as e:
                self.log_test("Media Directory", "FAIL", str(e))
    
    def test_7_cross_platform_compatibility(self):
        """Test 7: Cross-Platform Compatibility"""
        print(f"\n{Colors.BLUE}üåç Test Category 7: Cross-Platform Compatibility{Colors.ENDC}")
        
        # Test psutil availability and fallbacks
        try:
            import psutil
            self.log_test("psutil Availability", "PASS", "Enhanced monitoring available")
            
            # Test system monitoring functions
            memory_info = psutil.virtual_memory()
            self.log_test("System Monitoring", "PASS", f"Memory: {memory_info.total // (1024**3)}GB")
        except ImportError:
            self.log_test("psutil Availability", "WARN", "Using fallback monitoring")
            
            # Test fallback functionality
            try:
                from core.settings import get_memory_info
                memory_info = get_memory_info()
                if memory_info:
                    self.log_test("Fallback Monitoring", "PASS", "Fallback values working")
                else:
                    self.log_test("Fallback Monitoring", "FAIL", "Fallback failed")
            except Exception as e:
                self.log_test("Fallback Monitoring", "FAIL", str(e))
        
        # Test platform-specific features
        import platform
        system_info = {
            'system': platform.system(),
            'machine': platform.machine(),
            'platform': platform.platform()
        }
        
        self.log_test("Platform Detection", "PASS", 
                     f"{system_info['system']} {system_info['machine']}")
        
        # Test ARM64/RPi specific features if applicable
        if system_info['machine'] in ['aarch64', 'arm64']:
            self.log_test("ARM64 Support", "PASS", "ARM64 architecture detected")
            
            # Test RPi-specific features
            if Path('/proc/device-tree/model').exists():
                try:
                    with open('/proc/device-tree/model', 'r') as f:
                        model = f.read().strip('\x00')
                        if 'Raspberry Pi' in model:
                            self.log_test("Raspberry Pi Support", "PASS", f"Model: {model}")
                        else:
                            self.log_test("Raspberry Pi Support", "WARN", "Not a Raspberry Pi")
                except Exception as e:
                    self.log_test("Raspberry Pi Support", "FAIL", str(e))
    
    def test_8_performance_load(self):
        """Test 8: Performance and Load Testing"""
        print(f"\n{Colors.BLUE}‚ö° Test Category 8: Performance Testing{Colors.ENDC}")
        
        # Test database query performance
        start_time = time.time()
        try:
            # Test basic queries
            Personnel.objects.all().count()
            Item.objects.all().count()
            
            query_time = time.time() - start_time
            if query_time < 1.0:
                self.log_test("Database Query Performance", "PASS", f"{query_time:.3f}s")
            elif query_time < 3.0:
                self.log_test("Database Query Performance", "WARN", f"{query_time:.3f}s (slow)")
            else:
                self.log_test("Database Query Performance", "FAIL", f"{query_time:.3f}s (too slow)")
        except Exception as e:
            self.log_test("Database Query Performance", "FAIL", str(e))
        
        # Test page load performance
        performance_urls = ['/', '/personnel/', '/inventory/']
        
        for url in performance_urls:
            start_time = time.time()
            try:
                response = self.client.get(url)
                load_time = time.time() - start_time
                
                # Accept both 200 (authenticated) and 302 (redirect to login) as valid
                if response.status_code in [200, 302] and load_time < 2.0:
                    self.log_test(f"Page Load: {url}", "PASS", f"{load_time:.3f}s")
                elif response.status_code in [200, 302] and load_time < 5.0:
                    self.log_test(f"Page Load: {url}", "WARN", f"{load_time:.3f}s (slow)")
                else:
                    self.log_test(f"Page Load: {url}", "FAIL", 
                                f"Status: {response.status_code}, Time: {load_time:.3f}s")
            except Exception as e:
                self.log_test(f"Page Load: {url}", "FAIL", str(e))
        
        # Test memory usage
        try:
            import psutil
            import os
            process = psutil.Process(os.getpid())
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            if memory_mb < 100:
                self.log_test("Memory Usage", "PASS", f"{memory_mb:.1f}MB")
            elif memory_mb < 500:
                self.log_test("Memory Usage", "WARN", f"{memory_mb:.1f}MB (high)")
            else:
                self.log_test("Memory Usage", "FAIL", f"{memory_mb:.1f}MB (too high)")
        except ImportError:
            self.log_test("Memory Usage", "WARN", "Cannot measure (psutil not available)")
        except Exception as e:
            self.log_test("Memory Usage", "FAIL", str(e))
    
    def test_9_edge_cases_errors(self):
        """Test 9: Edge Cases and Error Handling"""
        print(f"\n{Colors.BLUE}üêõ Test Category 9: Edge Cases & Error Handling{Colors.ENDC}")
        
        # Test invalid URLs
        invalid_urls = [
            '/nonexistent/',
            '/admin/invalid/',
            '/api/personnel/INVALID-ID/',
            '/api/items/INVALID-ID/',
        ]
        
        for url in invalid_urls:
            try:
                response = self.client.get(url)
                if response.status_code == 404:
                    self.log_test(f"404 Handling: {url}", "PASS")
                elif response.status_code in [403, 302]:
                    self.log_test(f"Access Control: {url}", "PASS", f"Status: {response.status_code}")
                else:
                    self.log_test(f"Error Handling: {url}", "WARN", 
                                f"Unexpected status: {response.status_code}")
            except Exception as e:
                self.log_test(f"Error Handling: {url}", "FAIL", str(e))
        
        # Test invalid form data
        try:
            response = self.client.post('/login/', {
                'username': 'x' * 1000,  # Extremely long username
                'password': '',  # Empty password
            })
            # Should handle gracefully
            self.log_test("Invalid Form Data Handling", "PASS")
        except Exception as e:
            self.log_test("Invalid Form Data Handling", "FAIL", str(e))
        
        # Test database constraint violations
        try:
            with transaction.atomic():
                # Try to create duplicate personnel serial
                Personnel.objects.create(
                    serial='DUPLICATE-TEST',
                    firstname='First',
                    surname='User',
                    rank='1LT',
                    group='HAS',
                    tel='+639123456789'
                )
                
                try:
                    Personnel.objects.create(
                        serial='DUPLICATE-TEST',  # Same serial
                        firstname='Second',
                        surname='User',
                        rank='1LT',
                        group='HAS',
                        tel='+639123456789'
                    )
                    self.log_test("Duplicate ID Prevention", "FAIL", "Allowed duplicate serials")
                except Exception:
                    self.log_test("Duplicate ID Prevention", "PASS")
                    
        except Exception as e:
            self.log_test("Database Constraint Testing", "FAIL", str(e))
    
    def test_10_security_vulnerabilities(self):
        """Test 10: Security Vulnerability Scanning"""
        print(f"\n{Colors.BLUE}üõ°Ô∏è  Test Category 10: Security Vulnerabilities{Colors.ENDC}")
        
        # Test SQL injection protection
        try:
            malicious_inputs = [
                "'; DROP TABLE personnel; --",
                "' OR '1'='1",
                "admin'/*",
                "<script>alert('xss')</script>"
            ]
            
            for malicious_input in malicious_inputs:
                response = self.client.get(f'/api/personnel/{malicious_input}/')
                if response.status_code in [400, 404, 403]:
                    self.log_test("SQL Injection Protection", "PASS")
                    break
            else:
                self.log_test("SQL Injection Protection", "WARN", "Manual review needed")
        except Exception as e:
            self.log_test("SQL Injection Protection", "FAIL", str(e))
        
        # Test XSS protection
        try:
            xss_payloads = [
                "<script>alert('xss')</script>",
                "javascript:alert('xss')",
                "<img src=x onerror=alert('xss')>"
            ]
            
            for payload in xss_payloads:
                response = self.client.post('/login/', {
                    'username': payload,
                    'password': 'test'
                })
                # Should escape or reject
                if payload.encode() not in response.content:
                    self.log_test("XSS Protection", "PASS")
                    break
            else:
                self.log_test("XSS Protection", "WARN", "Manual review needed")
        except Exception as e:
            self.log_test("XSS Protection", "FAIL", str(e))
        
        # Test security headers
        try:
            response = self.client.get('/')
            security_headers = [
                'X-Content-Type-Options',
                'X-Frame-Options',
                'X-XSS-Protection',
                'Content-Security-Policy'
            ]
            
            missing_headers = []
            for header in security_headers:
                if header not in response:
                    missing_headers.append(header)
            
            if not missing_headers:
                self.log_test("Security Headers", "PASS")
            elif len(missing_headers) < 2:
                self.log_test("Security Headers", "WARN", f"Missing: {', '.join(missing_headers)}")
            else:
                self.log_test("Security Headers", "FAIL", f"Missing: {', '.join(missing_headers)}")
        except Exception as e:
            self.log_test("Security Headers", "FAIL", str(e))
    
    def generate_report(self):
        """Generate comprehensive test report"""
        end_time = time.time()
        duration = end_time - self.start_time
        
        print(f"\n{Colors.CYAN}{'='*80}{Colors.ENDC}")
        print(f"{Colors.CYAN}{Colors.BOLD}    Test Results Summary{Colors.ENDC}")
        print(f"{Colors.CYAN}{'='*80}{Colors.ENDC}")
        
        total_tests = self.test_results['passed'] + self.test_results['failed'] + self.test_results['warnings']
        
        print(f"\n{Colors.WHITE}Duration: {duration:.2f} seconds{Colors.ENDC}")
        print(f"{Colors.WHITE}Total Tests: {total_tests}{Colors.ENDC}")
        print(f"{Colors.GREEN}‚úÖ Passed: {self.test_results['passed']}{Colors.ENDC}")
        print(f"{Colors.YELLOW}‚ö†Ô∏è  Warnings: {self.test_results['warnings']}{Colors.ENDC}")
        print(f"{Colors.RED}‚ùå Failed: {self.test_results['failed']}{Colors.ENDC}")
        
        # Calculate success rate
        success_rate = (self.test_results['passed'] / total_tests * 100) if total_tests > 0 else 0
        
        print(f"\n{Colors.BOLD}Success Rate: {success_rate:.1f}%{Colors.ENDC}")
        
        if success_rate >= 95:
            print(f"{Colors.GREEN}{Colors.BOLD}üéâ EXCELLENT! Application is production ready{Colors.ENDC}")
        elif success_rate >= 85:
            print(f"{Colors.YELLOW}{Colors.BOLD}‚ö° GOOD! Minor issues to address{Colors.ENDC}")
        elif success_rate >= 70:
            print(f"{Colors.YELLOW}{Colors.BOLD}‚ö†Ô∏è  MODERATE! Several issues need attention{Colors.ENDC}")
        else:
            print(f"{Colors.RED}{Colors.BOLD}üîß NEEDS WORK! Critical issues found{Colors.ENDC}")
        
        # Show critical errors
        if self.test_results['errors']:
            print(f"\n{Colors.RED}{Colors.BOLD}üö® Critical Errors to Fix:{Colors.ENDC}")
            for error in self.test_results['errors']:
                print(f"{Colors.RED}  ‚Ä¢ {error}{Colors.ENDC}")
        
        # Show warnings
        if self.test_results['warnings_list']:
            print(f"\n{Colors.YELLOW}{Colors.BOLD}‚ö†Ô∏è  Warnings to Review:{Colors.ENDC}")
            for warning in self.test_results['warnings_list']:
                print(f"{Colors.YELLOW}  ‚Ä¢ {warning}{Colors.ENDC}")
        
        # Save detailed report
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'duration': duration,
            'summary': {
                'total_tests': total_tests,
                'passed': self.test_results['passed'],
                'warnings': self.test_results['warnings'],
                'failed': self.test_results['failed'],
                'success_rate': success_rate
            },
            'details': self.test_results['test_details'],
            'errors': self.test_results['errors'],
            'warnings': self.test_results['warnings_list']
        }
        
        report_file = f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(report_data, f, indent=2)
        
        print(f"\n{Colors.CYAN}üìÑ Detailed report saved to: {report_file}{Colors.ENDC}")
        
        return success_rate >= 85  # Return True if tests are generally passing
    
    def run_all_tests(self):
        """Execute all test categories"""
        self.print_banner()
        
        # Run gateway error check first
        self.test_0_gateway_error()
        # Run all test categories
        self.test_1_environment_setup()
        self.test_2_models_database()
        self.test_3_authentication_security()
        self.test_4_url_routing()
        self.test_5_api_endpoints()
        self.test_6_static_media_files()
        self.test_7_cross_platform_compatibility()
        self.test_8_performance_load()
        self.test_9_edge_cases_errors()
        self.test_10_security_vulnerabilities()
        
        # Generate final report
        return self.generate_report()

def main():
    """Main execution function"""
    print(f"{Colors.BOLD}Starting ArmGuard Comprehensive Test Suite...{Colors.ENDC}\n")
    
    suite = ComprehensiveTestSuite()
    success = suite.run_all_tests()
    
    if success:
        print(f"\n{Colors.GREEN}{Colors.BOLD}üöÄ Ready for deployment!{Colors.ENDC}")
        sys.exit(0)
    else:
        print(f"\n{Colors.RED}{Colors.BOLD}üîß Issues found - please fix and run again{Colors.ENDC}")
        sys.exit(1)

if __name__ == '__main__':
    main()
